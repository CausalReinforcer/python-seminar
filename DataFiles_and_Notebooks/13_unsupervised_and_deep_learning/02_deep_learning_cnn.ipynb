{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.asimovinstitute.org/wp-content/uploads/2016/09/neuralnetworks.png\">\n",
    "\n",
    "Source: http://www.asimovinstitute.org/neural-network-zoo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.fast.ai/images/001-google-dean.png\">\n",
    "\n",
    "Source: http://www.wsdm-conference.org/2016/slides/WSDM2016-Jeff-Dean.pdf\n",
    "This is a good, high-level overview of what's important/current in DNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\" Creating a deep learning model is, ironically, a highly manual process. Training a model takes a long time, and even for the top practitioners, it is a hit or miss affair where you donâ€™t know whether it will work until the end. No mature tools exist to ensure models train successfully, or to ensure that the original set up is done appropriately for the data.\" -- J. Howard (Fast.ai; http://www.fast.ai/2016/10/07/fastai-launch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Nets (CovNets)\n",
    "\n",
    "NNs built for images (or more generally, inputs with spatial structure).\n",
    "\n",
    "### Key Ideas: \n",
    "  - layers see only parts of each image (effectively all other weights are zero).\n",
    "  - some layers do simple operations on previous layers to reduce dimensionality (e.g., take the largest value in a a 3x3 range)\n",
    "  - \"Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.\"\n",
    " \n",
    "<img src=\"http://cs231n.github.io/assets/cnn/cnn.jpeg\">\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/depthcol.jpeg\">\n",
    "\n",
    "\"An example input volume in red (e.g. a 32x32x3 CIFAR-10 image), and an example volume of neurons in the first Convolutional layer. Each neuron in the convolutional layer is connected only to a local region in the input volume spatially, but to the full depth (i.e. all color channels). Note, there are multiple neurons (5 in this example) along the depth, all looking at the same region in the input - see discussion of depth columns in text below. \"\n",
    "\n",
    "cf. http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter banks\n",
    "\n",
    "  http://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/pool.jpeg\" width=\"40%\">\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/maxpool.jpeg\" width=\"40%\">\n",
    "Source: http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">sklearn is not build for deep/complex networks such as required in covnets. We must go to specialized software (and potentially specialized hardware)</div>\n",
    "\n",
    "# Deep Learning Frameworks\n",
    "\n",
    "Almost all frameworks written in low-level C++/C with Python (or other scripting bindings)\n",
    "\n",
    "### Low-level frameworks\n",
    "\n",
    "   - Tensorflow (Google) Nov 2015\n",
    "   - Theano\n",
    "   - Caffe (Berkeley)\n",
    "   - Torch (Lua)\n",
    "   - CNTK (Microsoft)\n",
    "   - PaddlePaddle (Baidu) Aug 2016\n",
    "   \n",
    "### High level frameworks (Python)\n",
    "\n",
    "   - Keras (atop Tensorflow, Theano)\n",
    "   - TFLearn \n",
    "   - nolearn\n",
    "   - SkFlow (part of tensorflow)\n",
    "   - [Lasagne](http://lasagne.readthedocs.io/en/latest/index.html) (atop Theano)\n",
    "   \n",
    "<img src=\"https://pbs.twimg.com/media/Cp6UW13UsAAQWWh.jpg\" width=\"75%\">\n",
    "Source: https://twitter.com/fchollet/status/765212287531495424/photo/1?ref_src=twsrc%5Etfw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as skflow\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn import datasets, metrics, cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "      iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skflow.DNNClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:Calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.980000\n"
     ]
    }
   ],
   "source": [
    "classifier = skflow.DNNClassifier(feature_columns=feature_columns,hidden_units=[10, 10], \n",
    "                                  n_classes=3,model_dir=\"/tmp/iris_model\")\n",
    "classifier.fit(iris.data, iris.target,steps=2000)\n",
    "score = metrics.accuracy_score(iris.target, classifier.predict(iris.data))\n",
    "print(\"Accuracy: %f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:Calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(classifier.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "### Simple Convnet - MNIST\n",
    "\n",
    "Slightly modified from mnist_cnn.py in the Keras examples folder:\n",
    "\n",
    "**https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py**\n",
    "\n",
    "https://github.com/transcranial/keras-js/blob/master/demos/notebooks/mnist_cnn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_FILEPATH = 'mnist_cnn.hdf5'\n",
    "MODEL_ARCH_FILEPATH = 'mnist_cnn.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=input_shape, dim_ordering='tf'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), border_mode='valid', dim_ordering='tf'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_11 (Convolution2D) (None, 26, 26, 32)    320         convolution2d_input_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 26, 26, 32)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 6, 6, 32)      0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 1152)          0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 1152)          0           flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 10)            11530       dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 10)            0           dense_16[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 11850\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot-ng\n",
      "  Downloading pydot_ng-1.0.0.zip\n",
      "Requirement already up-to-date: pyparsing>=2.0.1 in /Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages (from pydot-ng)\n",
      "Building wheels for collected packages: pydot-ng\n",
      "  Running setup.py bdist_wheel for pydot-ng ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/jbloom/Library/Caches/pip/wheels/4f/09/d5/f96fd2578831e1b9021c634f057ab5306a3e4287efa800de29\n",
      "Successfully built pydot-ng\n",
      "Installing collected packages: pydot-ng\n",
      "Successfully installed pydot-ng-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydot-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "Epoch 00000: val_acc improved from -inf to 0.97990, saving model to mnist_cnn.hdf5\n",
      "36s - loss: 0.0848 - acc: 0.9746 - val_loss: 0.0678 - val_acc: 0.9799\n",
      "Epoch 2/5\n",
      "Epoch 00001: val_acc improved from 0.97990 to 0.98100, saving model to mnist_cnn.hdf5\n",
      "36s - loss: 0.0791 - acc: 0.9764 - val_loss: 0.0624 - val_acc: 0.9810\n",
      "Epoch 3/5\n",
      "Epoch 00002: val_acc improved from 0.98100 to 0.98140, saving model to mnist_cnn.hdf5\n",
      "35s - loss: 0.0732 - acc: 0.9771 - val_loss: 0.0620 - val_acc: 0.9814\n",
      "Epoch 4/5\n",
      "Epoch 00003: val_acc did not improve\n",
      "38s - loss: 0.0702 - acc: 0.9786 - val_loss: 0.0603 - val_acc: 0.9812\n",
      "Epoch 5/5\n",
      "Epoch 00004: val_acc did not improve\n",
      "36s - loss: 0.0663 - acc: 0.9796 - val_loss: 0.0582 - val_acc: 0.9812\n",
      "Test score: 0.0582105874875\n",
      "Test accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# Model saving callback\n",
    "checkpointer = ModelCheckpoint(filepath=WEIGHTS_FILEPATH, \n",
    "                               monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Train\n",
    "batch_size = 128\n",
    "nb_epoch = 5\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=2,\n",
    "          callbacks=[checkpointer, early_stopping,TensorBoard(log_dir='/tmp/mnist')], \n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(MODEL_ARCH_FILEPATH, 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1208191d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmYQ/MfEKMgl/YuIVZBL+xMQryP8Hj7TmIMKUx/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120a12eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://transcranial.github.io/keras-js/#/mnist-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/cnn/convnet.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs231n.stanford.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): python-resize-image in /Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages\r\n",
      "Requirement already satisfied (use --upgrade to upgrade): pillow in /Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages (from python-resize-image)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-resize-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.vision.caltech.edu/Image_Datasets/Caltech101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jbloom/.keras/datasets/tmp/resized_img_00306.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a4462fe29ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m                                                                        \u001b[0mtest_imgs_per_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                                                                        shuffle=shuffle_data)\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshapex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshapey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'contain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshapex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshapey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'contain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a4462fe29ef8>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(X_path, resize, shapex, shapey, mode, quality, verbose)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2278\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jbloom/.keras/datasets/tmp/resized_img_00306.jpg'"
     ]
    }
   ],
   "source": [
    "# %load https://raw.githubusercontent.com/marcuniq/keras/ecf62d40cf03e3ccf849be1f820f3b5ba915f105/examples/caltech101_cnn.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import caltech101\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.normalization import LRN2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from six.moves import range\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "'''\n",
    "    Train a (fairly simple) deep CNN on the Caltech101 images dataset.\n",
    "    GPU run command:\n",
    "        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python caltech101_cnn.py\n",
    "'''\n",
    "\n",
    "\n",
    "def resize_imgs(fpaths, shapex, shapey, mode='contain', quality=90, verbose=0):\n",
    "    resized_fpaths = np.array([])\n",
    "\n",
    "    tmpdir = os.path.expanduser(os.path.join('~', '.keras', 'datasets', 'tmp'))\n",
    "    if os.path.exists(tmpdir):\n",
    "        #shutil.rmtree(tmpdir)\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(tmpdir)\n",
    "\n",
    "    try:\n",
    "        for i, f in enumerate(fpaths):\n",
    "            img = Image.open(f)\n",
    "            if mode is 'contain':\n",
    "                img = resizeimage.resize_contain(img, [shapex, shapey])\n",
    "            elif mode is 'crop':\n",
    "                img = resizeimage.resize_crop(img, [shapex, shapey])\n",
    "            elif mode is 'cover':\n",
    "                img = resizeimage.resize_crop(img, [shapex, shapey])\n",
    "            elif mode is 'thumbnail':\n",
    "                img = resizeimage.resize_thumbnail(img, [shapex, shapey])\n",
    "            elif mode is 'height':\n",
    "                img = resizeimage.resize_height(img, shapey)\n",
    "\n",
    "            _, extension = os.path.splitext(f)\n",
    "            out_file = os.path.join(tmpdir, 'resized_img_%05d%s' % (i, extension))\n",
    "            resized_fpaths = np.append(resized_fpaths, out_file)\n",
    "            if not os.path.exists:\n",
    "                img.save(out_file, img.format, quality=quality)\n",
    "                if verbose > 0:\n",
    "                    print(\"Resizing file : %s\" % (f))\n",
    "            img.close()\n",
    "    except e:\n",
    "        print(\"Error resize file : %s\" % (f))\n",
    "\n",
    "    return resized_fpaths\n",
    "\n",
    "\n",
    "def load_data(X_path, resize=True, shapex=240, shapey=180, mode='contain', quality=90, verbose=0):\n",
    "    if resize:\n",
    "        X_path = resize_imgs(X_path, shapex, shapey, mode=mode, quality=quality, verbose=verbose)\n",
    "\n",
    "    data = np.zeros((X_path.shape[0], 3, shapey, shapex), dtype=\"uint8\")\n",
    "\n",
    "    for i, f in enumerate(X_path):\n",
    "        img = Image.open(f)\n",
    "        r, g, b = img.split()\n",
    "        data[i, 0, :, :] = np.array(r)\n",
    "        data[i, 1, :, :] = np.array(g)\n",
    "        data[i, 2, :, :] = np.array(b)\n",
    "        img.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "# parameters\n",
    "batch_size = 4\n",
    "nb_classes = 102\n",
    "nb_epoch = 10\n",
    "data_augmentation = False\n",
    "\n",
    "shuffle_data = True\n",
    "\n",
    "# shape of the image (SHAPE x SHAPE)\n",
    "shapex, shapey = 240, 180\n",
    "\n",
    "# the caltech101 images are RGB\n",
    "image_dimensions = 3\n",
    "\n",
    "# load the data, shuffled and split between train and test sets\n",
    "print(\"Loading data...\")\n",
    "(X_train_path, y_train), (X_test_path, y_test) = caltech101.load_paths(train_imgs_per_category=15,\n",
    "                                                                       test_imgs_per_category=3,\n",
    "                                                                       shuffle=shuffle_data)\n",
    "X_train = load_data(X_train_path, shapex=shapex, shapey=shapey, mode='contain', verbose=1)\n",
    "X_test = load_data(X_test_path, shapex=shapex, shapey=shapey, mode='contain', verbose=1)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# cnn architecture from the CNN-S of http://arxiv.org/abs/1405.3531\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(96, 7, 7, subsample=(2, 2), input_shape=(image_dimensions, shapex, shapey)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(BatchNormalization(mode=1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), stride=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), stride=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), stride=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print('Compiling model...')\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print(\"Not using data augmentation or normalization\")\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True)\n",
    "    score = model.evaluate(X_test, Y_test, batch_size=batch_size, show_accuracy=True)\n",
    "    print('Test score:', score)\n",
    "\n",
    "else:\n",
    "    print(\"Using real time data augmentation\")\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    for e in range(nb_epoch):\n",
    "        print('-'*40)\n",
    "        print('Epoch', e)\n",
    "        print('-'*40)\n",
    "        print(\"Training...\")\n",
    "        # batch train with realtime data augmentation\n",
    "        progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        for X_batch, Y_batch in datagen.flow(X_train, Y_train):\n",
    "            loss = model.train_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        # test time!\n",
    "        progbar = generic_utils.Progbar(X_test.shape[0])\n",
    "        for X_batch, Y_batch in datagen.flow(X_test, Y_test):\n",
    "            score = model.test_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"test loss\", score)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
