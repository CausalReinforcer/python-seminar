{
 "metadata": {
  "name": "1_talking_to_computers"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python Seminar (AY250) UC Berkeley\n",
      "\n",
      "# Super simple webpage access"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import urllib2 # Uniform Resource Locator\n",
      "url = \"http://www.nist.gov/chem-srd-portal.cfm\"  # chemistry data portal\n",
      "response = urllib2.urlopen(url) # response is a file-like object\n",
      "html_data = response.read()\n",
      "response.close() # close response as you would a normal file\n",
      "print html_data[:300]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Small aside: if you have HTML data that you want to render, you can use `webbrowser` module\n",
      "\n",
      "see http://docs.python.org/library/webbrowser.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import webbrowser\n",
      "open(\"/tmp/tmp.html\",\"w\").write(html_data)\n",
      "webbrowser.open(\"file:///tmp/tmp.html\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scripting an HTTP GET request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2, urllib\n",
      "get_info = {\"q\": \"Ciechanover, Aaron\", \"sort\": \"relevance\"} # create a dictionary to store the GET data\n",
      "url_values = urllib.urlencode(get_info) # encode the data in proper url format\n",
      "print url_values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = \"http://pubget.com/search\"\n",
      "response = urllib2.urlopen(url,data=url_values) # open the url as before\n",
      "#alternatively: urllib2.urlopen(url + \"?\" + url_values)\n",
      "html = response.read()\n",
      "response.close()\n",
      "print html[:300]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scripting an HTTP POST request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2, urllib\n",
      "data = {}\n",
      "data[\"author\"] = \"Sagan, Carl\"\n",
      "params = urllib.urlencode(data) # same urlencode method\n",
      "url = \"http://adsabs.harvard.edu/cgi-bin/nph-abs_connect\"\n",
      "response = urllib2.urlopen(url, params) \n",
      "# POST request is indicated by including the params in urlopen\n",
      "html = response.read()\n",
      "response.close()\n",
      "print html[:300]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Access an FTP server"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ftplib\n",
      "ftp = ftplib.FTP(\"ftp.cac.psu.edu\")\n",
      "ftp.login()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftp.cwd(\"/pub/folk_music/sheet_music\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftp.dir()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftp.retrbinary('RETR OffToCalifornia.JPG', open('music.jpg', 'wb').write)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(12,16))\n",
      "im = plt.imread(\"music.jpg\")\n",
      "imshow(im, origin=\"lower\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Parsing HTML with BeautifulSoup\n",
      "\n",
      "See: http://www.crummy.com/software/BeautifulSoup/bs4/doc/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "response = urllib2.urlopen(\"http://words.bighugelabs.com/\")\n",
      "html = response.read()\n",
      "response.close()\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "soup = BeautifulSoup(html)\n",
      "forms = soup.findAll(\"form\")\n",
      "print(forms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "links = soup.findAll(\"a\")\n",
      "for link in links:\n",
      "    print link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember when you downloaded names for bears? We can do that easily by combining scripted webpage access with BeautifulSoup:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2, urllib\n",
      "from bs4 import BeautifulSoup\n",
      "letters = \"qwertyuioplkjhgfdsazxcvbnm\"\n",
      "boy_names = []\n",
      "for n in letters:\n",
      "    url = \"http://www.listofbabynames.org/\" + n + \"_boys.htm\"\n",
      "    response = urllib2.urlopen(url)\n",
      "    html = response.read()\n",
      "    response.close()\n",
      "    soup = BeautifulSoup(html)\n",
      "    items = soup.findAll(\"li\")\n",
      "    for item in items:\n",
      "        if not item.findAll(\"a\"):\n",
      "            boy_names.append(str(item.next).strip())\n",
      "boy_names.sort()\n",
      "print (str(len(boy_names)) + \" names from \" + boy_names[0] + \" to \" + boy_names[-1] + \".\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To demonstrate we downloaded and parsed all the names, and to have a little fun, let's make up an official-sounding, honorable name for a majestic bear."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "proper_bear_name = \"\"\n",
      "for n in range(5):\n",
      "    proper_bear_name += random.choice(boy_names) + \" \"\n",
      "proper_bear_name = \"Dr. \" + proper_bear_name[:-1] + \" XVI\" + \" DMD\"\n",
      "print proper_bear_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# JSON API"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json, urllib2\n",
      "import joshkey\n",
      "base_domain = \"http://words.bighugelabs.com/\"\n",
      "api_key =  joshkey.API # get your own damn key!\n",
      "word = \"dog\"\n",
      "url = base_domain + \"api/2/\" + api_key + \"/\" + word + \"/json\"\n",
      "result = json.load(urllib2.urlopen(url)) # a dictionary!\n",
      "print result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more fleshed-out example code, prints the output more cleanly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json, urllib2, sys\n",
      "base_domain = \"http://words.bighugelabs.com/\"\n",
      "api_key = \"483e281b60496d7961d852629799e733\"\n",
      "word = \"dog\"\n",
      "print \"Retrieving thesaurus entry for \\\"\" + word + \"\\\".\"\n",
      "url = base_domain + \"api/2/\" + api_key + \"/\" + word + \"/json\"\n",
      "try:\n",
      "    result = json.load(urllib2.urlopen(url)) # a dictionary!\n",
      "except:\n",
      "    print \"Error - word probably not in thesaurus.\"\n",
      "    sys.exit()\n",
      "for part_of_speech in result:\n",
      "    print \"-\"*50\n",
      "    print \"These are the \" + part_of_speech + \" entries:\"\n",
      "    for key in [\"syn\", \"ant\", \"rel\"]:\n",
      "        try:\n",
      "            for synonym in result[part_of_speech][key]:\n",
      "                print key + \" - \" + synonym\n",
      "        except:\n",
      "            continue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}