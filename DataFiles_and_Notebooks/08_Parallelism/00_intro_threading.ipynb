{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../00_AdvancedPythonConcepts/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "Python Computing for Data Science (AY250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline for Today\n",
    "\n",
    "- Motivation\n",
    "\n",
    "- Single-machine\n",
    "    - threading\n",
    "    - multiprocessing\n",
    "    - joblib\n",
    "    - dask\n",
    "- Multi-machine\n",
    "    - ipython cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Generally, the goal of your computing task is to finish as quickly as possible. The **speed of your processor** at executing instructions and the **speed at which data can be read from disk and from RAM** are major contributors to the execution time. Obviously the **choice of algorithm(s)** is critical too. Choosing an $N \\log N$ algorithm over a $N^2$ one that gets the same answer is almost always preferred for any sizeable $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Bottlenecks\n",
    "\n",
    "If you think of your run-time program as stream of data and computation on data, it should be clear that **bottlenecks are inevitable**. Your job (as you begin optimize for execution time) is to understand where those bottlenecks are and to use the tools we have in Python to minimize those. (Ultimately, it's a never-ending whack-a-mole).\n",
    "\n",
    "#### I/O Bound\n",
    "\n",
    "*\"a condition in which the time it takes to complete a computation is determined principally by the period spent waiting for input/output operations to be completed.\"* -- wikipedia\n",
    "\n",
    "This can be because we're waiting for a response from an external source (e.g. loading a webpage) or because data needs to be moved around on your bus and we're waiting for it to show up in the right place to compute on. If you have very fast CPUs, you're more likely to be I/O bound.\n",
    "\n",
    "#### CPU Bound\n",
    "\n",
    "*\"when the time for it to complete a task is determined principally by the speed of the central processor: processor utilization is high, perhaps at 100% usage for many seconds or minutes.\"* -- wikipedia\n",
    "\n",
    "If you're doing  algorithmic computations where the amount if input data is small and the amount of output data is also small (e.g. fournier transform) you'll typically be CPU bound. Slowed CPUs lead to more CPU bound bottlenecks. If you have a lot of data (\"big\") you're moving data around from disk, RAM, cache and you're likely I/O bound.\n",
    "\n",
    "#### (Memory Bound)\n",
    "\n",
    "\"time to complete a given computational problem is decided primarily by the amount of memory required to hold data\" - wikipedia.\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUUzntxvU9BHWJMZSH_CL3S7YRUjThJTrPEB/image.png\">\n",
    "\n",
    "Source: http://www.slideshare.net/ManojitNandi/parallel-programming-in-python-speeding-up-your-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes & Threads\n",
    "\n",
    "Each Python interpreter runs in a `process,` containing the program code, stack, and its current activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a process one can create a set of `threads` which share everything with the process in which they were spawned (memory, data, state). But, most generally, they are little programs (with their own stack) that execute `concurrently` (independent of each other). Since they share things like memory, it requires the programmer to \"lock\" everything that might conflict. The way we make many threads in Python is using the `threading` module.\n",
    "\n",
    "<div class=\"alert alert-info\">The Global Interpreter Lock (GIL) in Python stops threads from truly happening in parallel. That is, the interpreter can only operate one thread at a time. This is an impliementation detail of how CPython was programmed. Many things you use push threads down into the C-layer and \"avoid the GIL\". </div>\n",
    "\n",
    "You can also make many processes, which are copies of the original parent process (memory, data, state) and act independently of each other. To share data between them you have to explicitly do that within each process. The Pythonic way we do multiprocessing (creation of new processes, communication between processes) is with `multiprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of computing with `threading` and `multiprocessing` is to not wait around: the CPU should not be idle if it doesn't have too. AND since we almost always have multiple cores, we should be able to let the work we want to do happen in parallel over those cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading\n",
    "\n",
    "`threading.Thread(target=f, args=(...))` is the basic way to use function `f` with arguments in a thread.\n",
    "\n",
    "`.start()`: Calls the `.run()` of a thread object. This method will raise a `RuntimeError` if called more than once on the same thread object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Nice profile to let us profi\n",
    "!pip install snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 0\n",
      "Worker: 1\n",
      "Worker: 2\n",
      "Worker: 3\n",
      "Worker: 4\n",
      " \n",
      "*** Profile stats marshalled to file '/var/folders/dc/1sk9z_cx15s7g6895fqjlp7h0000gn/T/tmpy8s0duc7'. \n"
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "\n",
    "import threading\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    print('Worker: %s' % num)\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the GIL, threads wont get in each other's way if they are idle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-45) worker: 0 sleeping for 4 s, name: Thread-45\n",
      "(Thread-46) worker: 1 sleeping for 5 s, name: Thread-46\n",
      "(Thread-45) done\n",
      "(Thread-46) done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "import threading\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    \n",
    "    sleep_time = random.randint(1,5)\n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,threading.current_thread().getName()))\n",
    "    time.sleep(sleep_time)\n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-47) worker: 0 sleeping for 1 s, name: Thread-47\n",
      "(Thread-47) done\n",
      "(Thread-48) worker: 1 sleeping for 1 s, name: Thread-48\n",
      "(Thread-48) done\n"
     ]
    }
   ],
   "source": [
    "# not very parallel ... \n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    t.join() # this waits for the thread to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting around a bit, then starting threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-51) worker: 0 sleeping for 5 s, name: Thread-51\n",
      "(Thread-52) worker: 1 sleeping for 5 s, name: Thread-52\n",
      "(Thread-51) done\n",
      "(Thread-52) done\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "\n",
    "print(\"waiting around a bit, then starting threads\",flush=True)\n",
    "time.sleep(2)\n",
    "\n",
    "# dont have to start a thread immediately after creating them\n",
    "for t in threads:\n",
    "    t.start() \n",
    "\n",
    "for t in threads:\n",
    "    t.join() # this waits for the thread to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things:\n",
    "\n",
    "- `logging` is \"thread-safe\" -- so different threads can write to the log file without causing issues\n",
    "- you can always get a handle to the current thread with `threading.current_thread()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delay the start of the execution of a thread with `Timer`\n",
    "\n",
    "```python\n",
    "threading.Timer(interval, function, args=None, kwargs=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) starting Thread-165 with delay 5\n",
      "(MainThread) starting Thread-166 with delay 1\n",
      "(Thread-166) worker: 1 sleeping for 5 s, name: Thread-166\n",
      "(Thread-165) worker: 0 sleeping for 4 s, name: Thread-165\n",
      "(Thread-166) done\n",
      "(Thread-165) done\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "for i in range(2):\n",
    "    r = random.randint(1,5)\n",
    "    t = threading.Timer(r, worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    logging.debug(\"starting {0} with delay {1}\"\n",
    "                  .format(t.getName(),r))\n",
    "    threads[-1].start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can share variables (safely) between threads with a `queue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-156) worker: 0 sleeping for 4 s, name: Thread-156\n",
      "(Thread-157) worker: 1 sleeping for 2 s, name: Thread-157\n",
      "(Thread-157) initiated q = 2\n",
      "(Thread-157) done\n",
      "(Thread-156) var 2\n",
      "(Thread-156) added 4 to the q\n",
      "(Thread-156) done\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "def worker2(num):\n",
    "    sleep_time = random.randint(1,5)\n",
    "    \n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,threading.current_thread().getName()))\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    if q.empty():\n",
    "        q.put(sleep_time)\n",
    "        logging.debug(\"initiated q = {0}\".format(sleep_time))\n",
    "    else:\n",
    "        var = q.get()\n",
    "        logging.debug(\"var {0}\".format(var))\n",
    "        q.put(sleep_time + var)\n",
    "        logging.debug(\"added {0} to the q\".format(sleep_time))\n",
    "        \n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker2, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads can also signal each other with `Event` and can thresholds for the numbers of finished threads can be created with `Barrier`. There are low-level primiatives (pushed to the UNIX \\_pthreads level) called `locks` and `semaphores` that we'll not bother with here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threading can be done with objects. You can subclass `threading.Thread` and create your own threads that know how to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of google.com : is alive\n",
      "Status of slashdot.com : is alive\n",
      "Status of blasaskaslkas.org : not reachable\n"
     ]
    }
   ],
   "source": [
    "# adapted from http://www.python-course.eu/threads.php\n",
    "import os, re, threading\n",
    "\n",
    "received_packages = re.compile(r\"(\\d) packets received\")\n",
    "\n",
    "class ip_check(threading.Thread):\n",
    "  \n",
    "    def __init__ (self,ip):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.ip = ip\n",
    "      self.__successful_pings = -1\n",
    "   \n",
    "    def run(self):\n",
    "      ping_out = os.popen(\"ping -q -c2 \"+self.ip,\"r\")\n",
    "      while True:\n",
    "        lines = ping_out.readlines()\n",
    "        if not lines or len(lines) < 3: \n",
    "            break\n",
    "        n_received = re.findall(received_packages,lines[3])\n",
    "        if n_received:\n",
    "           self.__successful_pings = int(n_received[0])\n",
    "        \n",
    "    def status(self):\n",
    "      if self.__successful_pings == 0:\n",
    "         return \"has no response\"\n",
    "      elif self.__successful_pings == 1:\n",
    "         return \"is alive, but 50 % package loss\"\n",
    "      elif self.__successful_pings == 2:\n",
    "         return \"is alive\"\n",
    "      else:\n",
    "         return \"not reachable\"\n",
    "\n",
    "check_results = []\n",
    "for ip in [\"google.com\",\"slashdot.com\",\"blasaskaslkas.org\"]:\n",
    "   current = ip_check(ip)\n",
    "   check_results.append(current)\n",
    "   current.start()\n",
    "\n",
    "for el in check_results:\n",
    "   el.join()\n",
    "   print(\"Status of\", el.ip,el.status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PING cnn.com (157.166.226.26): 56 data bytes\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.popen(\"ping cnn.com\",\"r\").readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "\n",
    "Using threading, grab the titles of random 10 wikipedia webpages using https://en.wikipedia.org/wiki/Special:Random. Count the total number of characters returned over all 10 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: for asynchronous I/O tasks you might consider using an event loop. Use the built in `asyncio` and, for gathering webpages, use `aiohttp` (http://aiohttp.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Downloading aiohttp-1.0.2.tar.gz (499kB)\n",
      "\u001b[K    100% |████████████████████████████████| 501kB 839kB/s \n",
      "\u001b[?25hCollecting chardet (from aiohttp)\n",
      "  Downloading chardet-2.3.0.tar.gz (164kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 2.4MB/s \n",
      "\u001b[?25hCollecting multidict>=2.0 (from aiohttp)\n",
      "  Downloading multidict-2.1.0.tar.gz (92kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 4.6MB/s \n",
      "\u001b[?25hCollecting async_timeout (from aiohttp)\n",
      "  Downloading async_timeout-1.0.0-py3-none-any.whl\n",
      "Building wheels for collected packages: aiohttp, chardet, multidict\n",
      "  Running setup.py bdist_wheel for aiohttp ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/jbloom/Library/Caches/pip/wheels/e9/35/6c/73795198fbb6a3ca31348c296e412692089484e6dab19ae319\n",
      "  Running setup.py bdist_wheel for chardet ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/jbloom/Library/Caches/pip/wheels/28/8c/bf/a69199bd4901d84e13362f95a9ea7bc9a691fed2d655a90bc4\n",
      "  Running setup.py bdist_wheel for multidict ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/jbloom/Library/Caches/pip/wheels/aa/bc/05/36c01c37e6ab37a63278ee231003d8f843702bbd75c2b951fd\n",
      "Successfully built aiohttp chardet multidict\n",
      "Installing collected packages: chardet, multidict, async-timeout, aiohttp\n",
      "Successfully installed aiohttp-1.0.2 async-timeout-1.0.0 chardet-2.3.0 multidict-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title= 2007 Guatemala City sinkhole  len= 50691\n",
      "title= Kelnase  len= 32710\n",
      "title= C-ROT gate  len= 24909\n",
      "title= Dan McCarney  len= 62859\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python3.5\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.read()\n",
    "\n",
    "async def run(loop,  r):\n",
    "    url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "        for i in range(r):\n",
    "            task = asyncio.ensure_future(fetch(url, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        # you now have all response bodies in this variable\n",
    "    \n",
    "    for resp in responses:\n",
    "        print(\"title=\",BeautifulSoup(resp, 'html.parser')\n",
    "              .title.string.split(\"- Wikipedia\")[0],\"len=\",len(resp))\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(run(loop, 4))\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
