{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using PyTables and HDF5\n",
      "-----------------------\n",
      "UC Berkeley Python class (AY250; 2013)\n",
      "\n",
      "First we'll open a new HDF5 for writing (note: the \"w\" implies we will overwrite the file we have on disk)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from tables import *\n",
      "h5file = openFile(\"spam.h5\",mode = \"w\", title = \"PyTables/HDF5 test file\")\n",
      "h5file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "File(filename=spam.h5, title='PyTables/HDF5 test file', mode='w', rootUEP='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False))\n",
        "/ (RootGroup) 'PyTables/HDF5 test file'\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filters sets the protocols for the way all data will be treated in the file. fletcher32 = True, for instance will enforce checksums (slower, but more stable data), complevel is the compression level, etc.\n",
      "\n",
      "Now, let's create a 100x100 random image with createArray and associate it with a group called \"Datasets\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets = h5file.createGroup(h5file.root, \"Datasets\", \"Test data sets\")\n",
      "h5file.createArray(datasets, 'dataset1', np.random.random((100,100)), \"Test data set #1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "/Datasets/dataset1 (Array(100, 100)) 'Test data set #1'\n",
        "  atom := Float64Atom(shape=(), dflt=0.0)\n",
        "  maindim := 0\n",
        "  flavor := 'numpy'\n",
        "  byteorder := 'little'\n",
        "  chunkshape := None"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's create a complex object which we'll call a \"Particle\" that has the properties like name, atomic number, mass, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Particle(IsDescription):\n",
      "    name        = StringCol(16, pos=1) # 16-character String\n",
      "    atomic_num  = IntCol(pos=2)        # integer\n",
      "    mass        = FloatCol(pos=3)      # double (double-precision)\n",
      "    pressure    = Float32Col(shape=(2,3))\n",
      "table1 = h5file.createTable(datasets, \"particles\", Particle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row = table1.row\n",
      "row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "/Datasets/particles.row (Row), pointing to row #0"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add some data into the first particle"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row[\"name\"] = \"oxygen\"\n",
      "row[\"atomic_num\"] = 8\n",
      "row[\"mass\"] = 15.9994\n",
      "row[\"pressure\"] = [[1,2,3],[-1,1,3]]\n",
      "row.append() ; table1.flush()\n",
      "h5file.root.Datasets.particles[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "('oxygen', 8, 15.9994, [[1.0, 2.0, 3.0], [-1.0, 1.0, 3.0]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that, unlike numpy arrays, we can append new data. So this seems more like a DB in this respect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row = table1.row\n",
      "row[\"name\"] = \"perezium\"\n",
      "row[\"atomic_num\"] = 150\n",
      "row[\"mass\"] = 360.0\n",
      "row[\"pressure\"] = [[1,2,3],[1,0,3]]\n",
      "row.append() ; table1.flush()\n",
      "h5file.root.Datasets.particles[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "('shivversium', 150, 360.0, [[1.0, 2.0, 3.0], [1.0, 0.0, 3.0]])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [row['name'] for row in table1.where('atomic_num > 5 and mass < 100.0')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['oxygen']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}