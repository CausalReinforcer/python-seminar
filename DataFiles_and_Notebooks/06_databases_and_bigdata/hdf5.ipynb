{
 "metadata": {
  "name": "hdf5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using PyTables and HDF5\n",
      "-----------------------\n",
      "UC Berkeley Python class (AY250; 2012)\n",
      "\n",
      "First we'll open a new HDF5 for writing (note: the \"w\" implies we will overwrite the file we have on disk)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from tables import *\n",
      "h5file = openFile(\"spam.h5\",mode = \"w\", title = \"PyTables/HDF5 test file\")\n",
      "h5file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filters sets the protocols for the way all data will be treated in the file. fletcher32 = True, for instance will enforce checksums (slower, but more stable data), complevel is the compression level, etc.\n",
      "\n",
      "Now, let's create a 100x100 random image with createArray and associate it with a group called \"Datasets\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets = h5file.createGroup(h5file.root, \"Datasets\", \"Test data sets\")\n",
      "h5file.createArray(datasets, 'dataset1', np.random.random((100,100)), \"Test data set #1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's create a complex object which we'll call a \"Particle\" that has the properties like name, atomic number, mass, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Particle(IsDescription):\n",
      "    name        = StringCol(16, pos=1) # 16-character String\n",
      "    atomic_num  = IntCol(pos=2)        # integer\n",
      "    mass        = FloatCol(pos=3)      # double (double-precision)\n",
      "    pressure    = Float32Col(shape=(2,3))\n",
      "table1 = h5file.createTable(datasets, \"particles\", Particle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row = table1.row\n",
      "row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add some data into the first particle"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row[\"name\"] = \"oxygen\"\n",
      "row[\"atomic_num\"] = 8\n",
      "row[\"mass\"] = 15.9994\n",
      "row[\"pressure\"] = [[1,2,3],[-1,1,3]]\n",
      "row.append() ; table1.flush()\n",
      "h5file.root.Datasets.particles[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that, unlike numpy arrays, we can append new data. So this seems more like a DB in this respect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "row = table1.row\n",
      "row[\"name\"] = \"shivversium\"\n",
      "row[\"atomic_num\"] = 150\n",
      "row[\"mass\"] = 360.0\n",
      "row[\"pressure\"] = [[1,2,3],[1,0,3]]\n",
      "row.append() ; table1.flush()\n",
      "h5file.root.Datasets.particles[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [row['name'] for row in table1.where('atomic_num > 5 and mass < 100.0')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}